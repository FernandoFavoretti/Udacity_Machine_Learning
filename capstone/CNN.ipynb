{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "All the imports go here\n",
    "\n",
    "'''\n",
    "#scientific\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from PIL import Image\n",
    "\n",
    "#System\n",
    "import os\n",
    "import random\n",
    "from glob import glob\n",
    "\n",
    "#OpenCV\n",
    "import cv2\n",
    "\n",
    "#Tflearn\n",
    "import tflearn\n",
    "from tflearn.data_utils import shuffle, to_categorical\n",
    "from tflearn.layers.core import input_data, dropout, fully_connected\n",
    "from tflearn.layers.conv import conv_2d, max_pool_2d\n",
    "from tflearn.layers.estimator import regression\n",
    "from tflearn.data_preprocessing import ImagePreprocessing\n",
    "from tflearn.data_augmentation import ImageAugmentation\n",
    "from tflearn.metrics import Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "In this cell we entry with the location of the training folder and count the number of files on it\n",
    "'''\n",
    "\n",
    "images_dir = \"train/\"\n",
    "num_files = len(glob(os.path.join(images_dir, '*.jpg')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "The number of files in the folder are been used to start the numpy zeros arrays,\n",
    "preparing it to te target and the predictors variables.\n",
    "We also set the image size that we will use\n",
    "'''\n",
    "img_size = 64\n",
    "all_X = np.zeros((num_files, img_size, img_size, 3), dtype='float64')\n",
    "all_y = np.zeros(num_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "This function apply the histogram equalization in the image and after resize\n",
    "'''\n",
    "def transform_images(img, width, height):\n",
    "    img[:, :, 0] = cv2.equalizeHist(img[:, :, 0])\n",
    "    img[:, :, 1] = cv2.equalizeHist(img[:, :, 1])\n",
    "    img[:, :, 2] = cv2.equalizeHist(img[:, :, 2])\n",
    "    img = cv2.resize(img, (width, height), interpolation = cv2.INTER_CUBIC)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "The function bellow prepare the train set:\n",
    "We read all the images in the folder\n",
    "For each image we transform it (using transform_images above)\n",
    "And after put the image in the pre prepared all_X np array, also we put the label in the all_y array\n",
    "'''\n",
    "def make_train_set(data_folder):\n",
    "    i = 0\n",
    "    image_filenames = os.listdir(data_folder)\n",
    "    for image_filename in image_filenames:\n",
    "        image_path = os.path.join(data_folder, image_filename)\n",
    "        img = cv2.imread(image_path)\n",
    "        img = transform_images(img, img_size, img_size)\n",
    "        all_X[i] = np.array(img)\n",
    "        all_y[i] = 0 if 'dog' in str(image_filename) else 1\n",
    "        i += 1  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Running the function above\n",
    "make_train_set(images_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "With the sklearn train_test_split we prepare our test and train data\n",
    "The test size is 0.1 because bellow this the model didn't generalize well\n",
    "'''\n",
    "X, X_test, Y, Y_test = train_test_split(all_X, all_y, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Here we transform the label in complete arrays\n",
    "of the same size of the number of the classes we are trying to predictusing to_categorical\n",
    "it Converts a class vector (integers) to binary class matrix\n",
    "We using this for use with categorical_crossentropy after.\n",
    "'''\n",
    "Y = to_categorical(Y, 2)\n",
    "Y_test = to_categorical(Y_test, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "In this section we first normalized the mean and the standard deviation in the images:\n",
    "First we zero center every sample with specified mean.\n",
    "After  we scale each sample by the specified standard deviation.\n",
    "'''\n",
    "img_prepocessing = ImagePreprocessing()\n",
    "img_prepocessing.add_featurewise_zero_center()\n",
    "img_prepocessing.add_featurewise_stdnorm()\n",
    "\n",
    "\n",
    "'''\n",
    "Now, after some studies (Explaineds in the relatory),\n",
    "we use the Tf learn ImageAugmentation functions to rotate and flipping some of our images\n",
    "creating a synthetic training data\n",
    "'''\n",
    "img_aug = ImageAugmentation()\n",
    "img_aug.add_random_flip_leftright()\n",
    "img_aug.add_random_rotation(max_angle=25.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "This cell is the most important one, where we create our CNN\n",
    "    The input layer receive a 64x64 image with 3 color channels (RGB)\n",
    "    The layer number 1 is a Convolution layer with 32 filters, each 3x3x3. Sequel by a Max Pooling layer(2)\n",
    "    The layers numer 3 and 4 are convolution layers with 64 filters and RELU activation, sequels by a Max Pool Layer (5)\n",
    "    The layer numer 6 is a FC layer with about 512 nodes\n",
    "    The layer number 7 is a Droput layer, added to prevent overfitting\n",
    "    The Layer number 8 is a FC layer with two outputs and softmax activation\n",
    "    \n",
    "After that we configure how the network will be trained and prepare it into a model\n",
    "'''\n",
    "\n",
    "#input Layer\n",
    "network = input_data(shape=[None, 64, 64, 3],\n",
    "                     data_preprocessing=img_prepocessing,\n",
    "                     data_augmentation=img_aug)\n",
    "\n",
    "# Layer 1\n",
    "conv_1 = conv_2d(network, 32, 3, activation='relu', name='conv_1')\n",
    "\n",
    "# Layer 2\n",
    "network = max_pool_2d(conv_1, 2)\n",
    "\n",
    "# Layer 3\n",
    "conv_2 = conv_2d(network, 64, 3, activation='relu', name='conv_2')\n",
    "\n",
    "# Layer 4\n",
    "conv_3 = conv_2d(conv_2, 64, 3, activation='relu', name='conv_3')\n",
    "\n",
    "# Layer 5\n",
    "network = max_pool_2d(conv_3, 2)\n",
    "\n",
    "# Layer 6\n",
    "network = fully_connected(network, 512, activation='relu')\n",
    "\n",
    "# Layer 7\n",
    "network = dropout(network, 0.5)\n",
    "\n",
    "# Layer 8\n",
    "network = fully_connected(network, 2, activation='softmax')\n",
    "\n",
    "\n",
    "acc = Accuracy(name=\"Accuracy\")\n",
    "network = regression(network, optimizer='adam',\n",
    "                     loss='categorical_crossentropy',\n",
    "                     learning_rate=0.0005, metric=acc)\n",
    "\n",
    "\n",
    "model = tflearn.DNN(network, checkpoint_path='model_cat_dog_10.tflearn', max_checkpoints = 3,\n",
    "                    tensorboard_verbose = 3, tensorboard_dir='tmp/tflearn_logs/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "In this cell we train the CNN with a number N of epochs and save the logs to use with tensor board\n",
    "We also save the model to use to predict some images after all\n",
    "'''\n",
    "model.fit(X, Y, validation_set=(X_test, Y_test), batch_size=500,\n",
    "      n_epoch=10, run_id='model_cat_dog_10', show_metric=True)\n",
    "\n",
    "model.save('model_cat_dog_10_final.tflearn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
